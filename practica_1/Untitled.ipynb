{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura del fichero de texto\n",
    "f = open('instrumentos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Viol\\xedn. Instrumento musical de cuerda, el m\\xe1s peque\\xf1o y agudo entre los de su clase, que se compone de una caja de resonancia en forma de 8, un m\\xe1stil sin trastes y cuatro cuerdas que se hacen sonar con un arco.\\n\\nGuitarra.  Instrumento musical de cuerda compuesto por una caja de resonancia en forma de ocho, un m\\xe1stil largo con trastes, y cuerdas, generalmente seis, que se hacen sonar con los dedos.\\n\\nContrabajo. Instrumento musical de cuerda tocado con arco, el m\\xe1s grande y el de sonido m\\xe1s grave entre los de su familia.\\n\\n Tambor. Instrumento musical de percusi\\xf3n, de madera o metal, de forma cil\\xedndrica, hueco, cubierto por sus dos bases con piel estirada, que se toca con dos palillos.\\n\\nTromb\\xf3n. Instrumento musical de metal, especie de trompeta grande, y cuyos sonidos responden, seg\\xfan su clase, a las voces de tenor, contralto o bajo respectivamente.\\n\\nTrompeta. Instrumento musical de viento, consistente en un tubo largo de metal que va ensanch\\xe1ndose desde la boquilla al pabell\\xf3n y produce diversidad de sonidos seg\\xfan la fuerza con que la boca impele el aire.\\n\\nViolonchelo. Instrumento musical de cuerda tocado con arco, m\\xe1s grande que la viola y m\\xe1s peque\\xf1o que el contrabajo y con un registro intermedio entre ambos. El int\\xe9rprete, que est\\xe1 sentado, lo coloca entre sus piernas para tocarlo.\\n\\nAcorde\\xf3n. Instrumento musical de viento, formado por un fuelle cuyos dos extremos se cierran por sendas cajas, especie de estuches, en los que juegan cierto n\\xfamero de llaves o teclas que permiten seleccionar los sonidos.\\n\\nFlauta. Instrumento musical de viento, de madera u otro material, en forma de tubo con varios agujeros circulares que se tapan con los dedos o con llaves.\\n\\nXil\\xf3fono. Instrumento musical de percusi\\xf3n formado por l\\xe1minas generalmente de madera, ordenadas horizontalmente seg\\xfan su tama\\xf1o y sonido, que se hacen sonar golpe\\xe1ndolas con dos baquetas.\\n\\nPiano. Instrumento musical de cuerdas generalmente met\\xe1licas dispuestas dentro de una caja de resonancia, que son golpeadas por macillos accionados desde un teclado.\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-465eb410cd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "words.encode('utf8')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/Users/pablohidalgo/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - u''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9e3aac1c30e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/pablohidalgo/anaconda2/lib/python2.7/site-packages/nltk/tokenize/__init__.pyc\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 130\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m",
      "\u001b[0;32m/Users/pablohidalgo/anaconda2/lib/python2.7/site-packages/nltk/tokenize/__init__.pyc\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreebankWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pablohidalgo/anaconda2/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             raise ValueError('Could not determine format for %s based '\n\u001b[0;32m--> 814\u001b[0;31m                              \u001b[0;34m'on its file\\nextension; use the \"format\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                              \u001b[0;34m'argument to specify the format explicitly.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                              % resource_url)\n",
      "\u001b[0;32m/Users/pablohidalgo/anaconda2/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \"\"\"\n\u001b[1;32m    931\u001b[0m     \u001b[0m_resource_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pablohidalgo/anaconda2/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m                                      [pieces[i] + '.zip'] + pieces[i:])\n\u001b[1;32m    652\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/Users/pablohidalgo/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - u''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import sys\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "#Lectura del fichero de texto\n",
    "f = open ('instrumentos.txt')\n",
    "freqdist = nltk.FreqDist()\n",
    "words=nltk.word_tokenize(f.read())\n",
    "fd = nltk.FreqDist(word.lower() for word in words)\n",
    "fdf= fd.most_common(50)\n",
    "\n",
    "print 'Palabras del texto ordenadas por frecuencia'\n",
    "t=''\n",
    "for w in fdf:\n",
    "    t+='('+w[0]+','+str(w[1])+') '\n",
    "print t\n",
    "\n",
    "\n",
    "dict ={}\n",
    "dict['.']='PUNT'\n",
    "dict['la']='DET'\n",
    "dict['a']='PREP'\n",
    "dict['para']='PREP'\n",
    "dict['que']='CONJ'\n",
    "dict['en']='PREP'\n",
    "dict['el']='DET'\n",
    "#Aquí hay se añaden las palabras del diccionario y sus etiquetas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p=[\n",
    "    (r'.*amos$','VIP1S'),\n",
    "    (r'.*imos$','VIP1S'),\n",
    "    (r'.*a$','NCFS'),\n",
    "    (r'.*$','NCMS'),\n",
    "    #Aquí hay se añaden los patrones necesarios\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "rt=nltk.RegexpTagger(p)\n",
    "taggedText=rt.tag(words)\n",
    "for item in taggedText:\n",
    "    if dict.has_key(item[0]):\n",
    "        print item[0]+' '+dict[item[0]]\n",
    "    else:\n",
    "        print item[0]+' '+item[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 'PUNT',\n",
       " 'a': 'PREP',\n",
       " 'el': 'DET',\n",
       " 'en': 'PREP',\n",
       " 'la': 'DET',\n",
       " 'para': 'PREP',\n",
       " 'que': 'CONJ'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
